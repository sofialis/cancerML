{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "import sklearn.linear_model as sklm\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score, log_loss\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The constant number of possible disease outcomes\n",
    "# 0: Complete Remission/Response\n",
    "# 1: Stable Disease\n",
    "# 2: Progressive Disease\n",
    "# 3: Partial Remission/Response\n",
    "# 4: Persistent Disease\n",
    "OUTCOMES_NUM = 5\n",
    "\n",
    "# The number of cross-validation train groups\n",
    "CV_GROUPS = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Prediction: Vital status**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vital_status_train(X, y, alpha, iters, feature_labels, runs = 1, details = True):\n",
    "    \"\"\"\n",
    "    Trains the models to predict the vital status of a patient by the end of cancer treatment.\n",
    "\n",
    "    :param X: The input matrix (ndarray)\n",
    "    :param y: The output vector (ndarray)\n",
    "    :param alpha: The gradient descent coefficient (float)\n",
    "    :param iters: The number of gradient descent iterations (int)\n",
    "    :param feature_labels: The list of feature labels (list)\n",
    "    :param runs: The number of times to train the model (int)\n",
    "    :param details: True for the full output (bool)\n",
    "    \n",
    "    \"\"\"    \n",
    "    # Display only the average accuracies\n",
    "    if not details:\n",
    "        class_accuracy = train_accuracy = test_accuracy = bayes_accuracy = 0\n",
    "        \n",
    "        # Accumulate accuracy statistics for each training batch\n",
    "        for i in range(runs):              \n",
    "            # Get training data and train the models\n",
    "            X_groups, y_groups, X_groups_full, y_groups_full = get_vital_status_data(X, y)\n",
    "            class_acc = vital_status_manual(X_groups, y_groups, alpha, iters, details)\n",
    "            tr_acc, ts_acc, bs_acc = vital_status_scikit(X_groups, y_groups, X_groups_full, y_groups_full, \\\n",
    "                                                         feature_labels, details)               \n",
    "            class_accuracy = class_accuracy + class_acc\n",
    "            train_accuracy = train_accuracy + tr_acc\n",
    "            test_accuracy = test_accuracy + ts_acc\n",
    "            bayes_accuracy = bayes_accuracy + bs_acc\n",
    "        print(\"Logistic Regression (manual):\")\n",
    "        print(\"Average test accuracy: %.2f\" % (class_accuracy/runs),\"%\")\n",
    "        print(\"Logistic Regression (scikit):\")      \n",
    "        print(\"Average train accuracy: %.2f\" % (train_accuracy/runs),\"%\")\n",
    "        print(\"Average test accuracy: %.2f\" % (test_accuracy/runs),\"%\")\n",
    "        print(\"Bayes (scikit):\")\n",
    "        print(\"Average test accuracy: %.2f\" % (bayes_accuracy/runs),\"%\") \n",
    "    \n",
    "    # Display the full statistics and graphics\n",
    "    else:\n",
    "        for i in range(runs):             \n",
    "            # Get training data and train the models\n",
    "            X_groups, y_groups, X_groups_full, y_groups_full = get_vital_status_data(X, y)\n",
    "            print(\"Logistic Regression (manual):\")\n",
    "            vital_status_manual(X_groups, y_groups, alpha, iters, details)\n",
    "            print(\"Logistic Regression (scikit):\") \n",
    "            vital_status_scikit(X_groups, y_groups, X_groups_full, y_groups_full, \\\n",
    "                                feature_labels, details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vital_status_data(X, y):  \n",
    "    \"\"\"\n",
    "    Returns the cross-validation groups for the vital status training.\n",
    "\n",
    "    :param X: The input matrix (ndarray)\n",
    "    :param y: The output vector (ndarray)\n",
    "\n",
    "    :return X_groups: Balanced cross-validation groups for X (list)\n",
    "    :return y_groups: Balanced cross-validation groups for y (list)\n",
    "    :return X_groups_full: Cross-validation groups for X that include all cases (list)\n",
    "    :return y_groups_full: Cross-validation groups for y that include all cases (list)\n",
    "        \n",
    "    \"\"\"    \n",
    "    # Separate and shuffle all cases\n",
    "    dead_full = np.nonzero(y == 0)[0]\n",
    "    alive_full = np.nonzero(y == 1)[0]\n",
    "    np.random.shuffle(dead_full)\n",
    "    np.random.shuffle(alive_full)\n",
    "    \n",
    "    # Equate the number of different types for manual model\n",
    "    num_cases = min(len(dead_full), len(alive_full))\n",
    "    dead = dead_full[0:num_cases]\n",
    "    alive = alive_full[0:num_cases]\n",
    "    \n",
    "    # Split each type into cross-validation train groups\n",
    "    dead_full_groups = np.array_split(dead_full, CV_GROUPS)\n",
    "    alive_full_groups = np.array_split(alive_full, CV_GROUPS)\n",
    "    dead_groups = np.array_split(dead, CV_GROUPS)\n",
    "    alive_groups = np.array_split(alive, CV_GROUPS)\n",
    "    \n",
    "    # Accumulate the groups in lists\n",
    "    subsets = []\n",
    "    subsets_full = []\n",
    "    for i in range(CV_GROUPS):\n",
    "        subsets_full.append(np.concatenate((dead_full_groups[i], alive_full_groups[i])))\n",
    "        np.random.shuffle(subsets_full[i]) \n",
    "        subsets.append(np.concatenate((dead_groups[i], alive_groups[i])))      \n",
    "        np.random.shuffle(subsets[i])\n",
    "\n",
    "    # Form the cross-validation groups using all possible types\n",
    "    X_groups = []\n",
    "    y_groups = []\n",
    "    X_groups_full = []\n",
    "    y_groups_full = []\n",
    "    for i in range(CV_GROUPS):\n",
    "        X_groups_full.append(X[subsets_full[i],:])\n",
    "        y_groups_full.append(y[subsets_full[i]])      \n",
    "        X_groups.append(X[subsets[i],:])\n",
    "        y_groups.append(y[subsets[i]])\n",
    "        \n",
    "    return X_groups, y_groups, X_groups_full, y_groups_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vital_status_manual(X_groups, y_groups, alpha, iters, details = True,  included = [0, 1]):\n",
    "    \"\"\"\n",
    "    Trains the manual model to predict the vital status.\n",
    "\n",
    "    :param X_groups: The cross-validation groups for X (list)\n",
    "    :param y_groups: The cross-validation groups for y (list) \n",
    "    :param alpha: The gradient descent coefficient (float)\n",
    "    :param iters: The number of gradient descent iterations (int)\n",
    "    :param details: True for the full output (bool)\n",
    "    :param included: The classes to include (list)\n",
    "\n",
    "    :return: Average logistic regression test accuracy (float)\n",
    "        \n",
    "    \"\"\"\n",
    "    # Define parameters for the training\n",
    "    theta = np.ones(X_groups[0].shape[1])\n",
    "    train_accuracy = test_accuracy = train_f1_score = test_f1_score = 0\n",
    "    gradient_cost = 0\n",
    "    test_confusion = np.zeros(shape=(2, 2))\n",
    "\n",
    "    # Train on the all groups but the test one\n",
    "    for i in range(CV_GROUPS):\n",
    "        # Get train/test X and y batches\n",
    "        X_train, y_train = get_train_groups(X_groups, y_groups, i)\n",
    "        X_test = X_groups[i]\n",
    "        y_test = y_groups[i]\n",
    "        \n",
    "        # Train the manual model\n",
    "        theta, J = gradient_descent(X_train, y_train, theta, alpha, iters)\n",
    "        gradient_cost = gradient_cost + J[-1]\n",
    "               \n",
    "        # Get train and test predictions\n",
    "        sort_predictions = lambda x: 0 if x < 0.5 else 1\n",
    "        convert_to_log = np.vectorize(sort_predictions)\n",
    "        train_preds = logistic(np.dot(X_train, theta))\n",
    "        train_preds = convert_to_log(train_preds)\n",
    "        test_preds = logistic(np.dot(X_test, theta))\n",
    "        test_preds = convert_to_log(test_preds)\n",
    "        \n",
    "        # Get the statistics\n",
    "        accuracy, f1 = get_stats(y_train, train_preds)\n",
    "        train_accuracy = train_accuracy + accuracy\n",
    "        train_f1_score = train_f1_score + f1\n",
    "        accuracy, f1 = get_stats(y_test, test_preds)\n",
    "        test_accuracy = test_accuracy + accuracy\n",
    "        test_f1_score = test_f1_score + f1\n",
    "        test_confusion = test_confusion + confusion_matrix(y_test, test_preds)\n",
    "    \n",
    "    # Display the full statistics and graphics\n",
    "    if details:\n",
    "        print(\"Average train final cost: %.2f\" % (gradient_cost/CV_GROUPS))\n",
    "        print(\"Average train accuracy: %.2f\" % (train_accuracy/CV_GROUPS),\"%\")\n",
    "        print(\"Average train F1 score: %.2f\" % (train_f1_score/CV_GROUPS))\n",
    "        print(\"Average test accuracy: %.2f\" % (test_accuracy/CV_GROUPS),\"%\")\n",
    "        print(\"Average test F1 score: %.2f\" % (test_f1_score/CV_GROUPS))\n",
    "        create_heatmap((test_confusion/CV_GROUPS).astype('int'), included)\n",
    "        \n",
    "    return test_accuracy/CV_GROUPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vital_status_scikit(X_groups, y_groups, X_groups_full, y_groups_full, feature_labels, details = True):\n",
    "    \"\"\"\n",
    "    Trains the scikit model to predict the vital status.\n",
    "\n",
    "    :param X_groups: The cross-validation groups for reduced X (list)\n",
    "    :param y_groups: The cross-validation groups for reduced y (list) \n",
    "    :param X_groups_full: The cross-validation groups for full X (list)\n",
    "    :param y_groups_full: The cross-validation groups for full y (list) \n",
    "    :param feature_labels: The list of feature labels (list)\n",
    "    :param details: True for the full output (bool)\n",
    "    \n",
    "    :return: Average logistic regression train accuracy (float)\n",
    "    :return: Average logistic regression test accuracy (float)\n",
    "    :return: Average Bayes test accuracy (float)\n",
    "        \n",
    "    \"\"\"    \n",
    "    # Define parameters for the training\n",
    "    train_accuracy = test_accuracy = bayes_accuracy = 0\n",
    "    train_cost = test_cost = 0\n",
    "    train_f1_score = test_f1_score = bayes_f1_score = 0\n",
    "    test_weights = np.zeros(X_groups[0].shape[1] - 1)\n",
    "    test_confusion = np.zeros(shape=(2, 2)) \n",
    "    \n",
    "    for i in range(CV_GROUPS):\n",
    "        # Get train/test X and y batches\n",
    "        X_train, y_train = get_train_groups(X_groups, y_groups, i)\n",
    "        X_train_full, y_train_full = get_train_groups(X_groups_full, y_groups_full, i)\n",
    "        X_test = X_groups[i]\n",
    "        y_test = y_groups[i] \n",
    "        X_test_full = X_groups_full[i]\n",
    "        y_test_full = y_groups_full[i] \n",
    "        \n",
    "        # Train the Logistic Regression and Gaussian Bayes models\n",
    "        lr = sklm.LogisticRegression(solver='liblinear', class_weight = 'balanced')\n",
    "        lr.fit(X_train_full[:,1:], y_train_full)\n",
    "        gnb = GaussianNB()\n",
    "        gnb.fit(X_train[:,1:], y_train)\n",
    "        \n",
    "        # Get train and test predictions\n",
    "        train_preds = lr.predict(X_train_full[:,1:])\n",
    "        test_preds = lr.predict(X_test_full[:,1:])\n",
    "        gnb_preds = gnb.predict(X_test[:,1:])\n",
    "        \n",
    "        # Get the statistics\n",
    "        bayes_accuracy = bayes_accuracy + accuracy_score(y_test, gnb_preds)*100\n",
    "        bayes_f1_score = bayes_f1_score + f1_score(y_test, gnb_preds)       \n",
    "        train_accuracy = train_accuracy + accuracy_score(y_train_full, train_preds)*100\n",
    "        train_f1_score = train_f1_score + f1_score(y_train_full, train_preds)\n",
    "        train_cost = train_cost + log_loss(y_train_full, train_preds)        \n",
    "        test_accuracy = test_accuracy + accuracy_score(y_test_full, test_preds)*100\n",
    "        test_f1_score = test_f1_score + f1_score(y_test_full, test_preds)\n",
    "        test_cost = test_cost + log_loss(y_test_full, test_preds)        \n",
    "        test_weights = np.add(test_weights, lr.coef_[0])\n",
    "        test_confusion = test_confusion + confusion_matrix(y_test_full, test_preds)\n",
    "\n",
    "    # Get the labels with the highest average absolute weights\n",
    "    actual_labels, actual_weights = get_actual_weights(feature_labels[1:], list(test_weights))    \n",
    "    test_weights_abs = list(np.abs(actual_weights))\n",
    "    test_weights_sorted = test_weights_abs.copy()\n",
    "    test_weights_sorted.sort(reverse = True)\n",
    "    \n",
    "    # Display the full statistics and graphics\n",
    "    if details:\n",
    "        print(\"Average train final cost: %.2f\" % (train_cost/CV_GROUPS))\n",
    "        print(\"Average train accuracy: %.2f\" % (train_accuracy/CV_GROUPS),\"%\")\n",
    "        print(\"Average train F1 score: %.2f\" % (train_f1_score/CV_GROUPS))\n",
    "        print(\"Average test final cost: %.2f\" % (test_cost/CV_GROUPS))\n",
    "        print(\"Average test accuracy: %.2f\" % (test_accuracy/CV_GROUPS),\"%\")\n",
    "        print(\"Average test F1 score: %.2f\" % (test_f1_score/CV_GROUPS))\n",
    "        print(\"Average Gaussian Naive Bayes accuracy: %.2f\" % (bayes_accuracy/CV_GROUPS),\"%\")\n",
    "        print(\"Average Gaussian Naive Bayes F1 score: %.2f\" % (bayes_f1_score/CV_GROUPS))\n",
    "        create_heatmap((test_confusion/CV_GROUPS).astype('int'), [0, 1])\n",
    "        print()\n",
    "        print(\"Highest average weights (absolute values):\")\n",
    "        for i in range(len(test_weights_sorted[:3])):\n",
    "            index = test_weights_abs.index(test_weights_sorted[i])\n",
    "            print(actual_labels[index], ': %.2f' % test_weights_sorted[i])\n",
    "            \n",
    "    return train_accuracy/CV_GROUPS, test_accuracy/CV_GROUPS, bayes_accuracy/CV_GROUPS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Prediction: Life expectancy (in days)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def life_expectancy_train(X, y, alpha, iters):\n",
    "    \"\"\"\n",
    "    Trains the models to predict the life expectancy of a patient in days.\n",
    "\n",
    "    :param X: The input matrix (ndarray)\n",
    "    :param y: The output vector (ndarray)\n",
    "    :param alpha: The gradient descent coefficient (float)\n",
    "    :param iters: The number of gradient descent iterations (int)\n",
    "    \n",
    "    \"\"\"  \n",
    "    train_accuracy = test_accuracy = final_cost = 0\n",
    "    \n",
    "    # Get cross-validation grouped X and y data\n",
    "    X_groups, y_groups = get_life_expectancy_data(X, y)\n",
    "\n",
    "    # Perform k-fold cross-validation and record the results \n",
    "    for i in range(CV_GROUPS):\n",
    "        X_test = X_groups[i]\n",
    "        y_test = y_groups[i]\n",
    "        X_train, y_train = get_train_groups(X_groups, y_groups, i)\n",
    "\n",
    "        # Scikit model training\n",
    "        lr = sklm.LinearRegression()\n",
    "        lr.fit(X_train, y_train)\n",
    "        train_preds = lr.predict(X_train)\n",
    "        test_preds = lr.predict(X_test)\n",
    "\n",
    "        # Manual training, only cost\n",
    "        theta_vec_equations, cost = gradient_descent_v2(normalize_v2(X_train), y_train, alpha, iters)   \n",
    "        final_cost = final_cost + cost[-1]\n",
    "\n",
    "        # Calculate the train accuracy within the 180 days margin\n",
    "        match = 0\n",
    "        for i in range(len(y_train)):\n",
    "            if  train_preds[i] <= y_train[i] + 180 and train_preds[i] >= y_train[i] - 180:\n",
    "                match += 1\n",
    "        train_accuracy = train_accuracy + match/len(y_train)*100 \n",
    "\n",
    "        # Calculate the test accuracy within the 180 days margin\n",
    "        match = 0\n",
    "        for i in range(len(y_test)):\n",
    "            if  test_preds[i] <= y_test[i] + 180 and test_preds[i] >= y_test[i] - 180:\n",
    "                match += 1\n",
    "        test_accuracy = test_accuracy + match/len(y_test)*100 \n",
    "\n",
    "    print(\"Manual model:\")\n",
    "    print(\"Average final cost: %.2f\" % (final_cost/CV_GROUPS))\n",
    "    print(\"Mean in y: %.2f\" % np.mean(y))\n",
    "    print(\"Variance in y: %.2f\" % np.var(y))\n",
    "    print()\n",
    "    print(\"Scikit model:\")\n",
    "    print(\"Average train accuracy: %.2f\" % (train_accuracy/CV_GROUPS),\"%\")\n",
    "    print(\"Average test accuracy: %.2f\" % (test_accuracy/CV_GROUPS),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_life_expectancy_data(X, y):    \n",
    "    \"\"\"\n",
    "    Returns the cross-validation groups for the life expectancy training.\n",
    "\n",
    "    :param X: The input matrix (ndarray)\n",
    "    :param y: The output vector (ndarray)\n",
    "\n",
    "    :return X_groups: Cross-validation groups for X (list)\n",
    "    :return y_groups: Cross-validation groups for y (list)\n",
    "        \n",
    "    \"\"\"  \n",
    "    # Get all deceased cases\n",
    "    death_indices = np.arange(len(y))\n",
    "    np.random.shuffle(death_indices)\n",
    "    \n",
    "    dead_groups = np.array_split(death_indices, CV_GROUPS)\n",
    "\n",
    "    X_groups = []\n",
    "    y_groups = []\n",
    "    for i in range(CV_GROUPS):\n",
    "        X_groups.append(X[dead_groups[i],:])\n",
    "        y_groups.append(y[dead_groups[i]])\n",
    "    return X_groups, y_groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Prediction: Cancer outcome**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outcome_train(X, y, included, lambda_val, feature_labels, \\\n",
    "                  alpha = 0.00000001, iters = 2000, runs = 1, details = True):\n",
    "    \"\"\"\n",
    "    Trains the models to predict the outcome of the disease.\n",
    "\n",
    "    :param X: The input matrix (ndarray)\n",
    "    :param y: The output vector (ndarray)\n",
    "    :param lambda_val: Regularization parameter (float)\n",
    "    :param feature_labels: The feature labels (list)\n",
    "    :param alpha: The gradient descent coefficient (float)\n",
    "    :param iters: The number of gradient descent iterations (int)\n",
    "    :param runs: The number of times to train the model (int)\n",
    "    :param details: True for the full output (bool)\n",
    "        \n",
    "    \"\"\"  \n",
    "    num_classes = len(included)\n",
    "    \n",
    "    if details == True:\n",
    "        for i in range(runs):    \n",
    "            X_groups, y_groups = get_outcome_data(X, y, included)\n",
    "\n",
    "            print(\"Manual model:\")\n",
    "            if num_classes == 2:\n",
    "                for i in range(len(y_groups)):\n",
    "                    y_groups[i] = np.where(y_groups[i] == included[0], 0, 1)                    \n",
    "                print(\"Logistic regression:\")\n",
    "                # Reuse the vital status training implementation for binary classification\n",
    "                vital_status_manual(X_groups, y_groups, alpha, iters, included = included)\n",
    "                print()\n",
    "\n",
    "            print(\"One vs all:\")  \n",
    "            outcome_manual(X_groups, y_groups, included, lambda_val)\n",
    "            print()\n",
    "            \n",
    "            print(\"Scikit model:\")\n",
    "            outcome_scikit(X_groups, y_groups, included, feature_labels)\n",
    "            plot_lambdas(X_groups, y_groups, included)\n",
    "    else:\n",
    "        acc_regression = acc_classifier = acc_scikit = acc_bayes = 0\n",
    "        \n",
    "        for i in range(runs):  \n",
    "            X_groups, y_groups = get_outcome_data(X, y, included)\n",
    "\n",
    "            if num_classes == 2:\n",
    "                for i in range(len(y_groups)):\n",
    "                    y_groups[i] = np.where(y_groups[i] == included[0], 0, 1)                    \n",
    "                acc_regression = acc_regression + vital_status_manual(X_groups, y_groups, alpha, iters, details) \n",
    "            acc_classifier = acc_classifier + outcome_manual(X_groups, y_groups, included, lambda_val, details)\n",
    "            test_scikit, test_bayes = outcome_scikit(X_groups, y_groups, included, feature_labels, details)\n",
    "            acc_scikit = acc_scikit + test_scikit       \n",
    "            acc_bayes = acc_bayes + test_bayes    \n",
    "                \n",
    "        if num_classes == 2:\n",
    "            print(\"Logistic regression:\")\n",
    "            print(\"Average test accuracy: %.2f\" % (acc_regression/runs),\"%\")\n",
    "        print(\"One vs all model:\")\n",
    "        print(\"Average test accuracy: %.2f\" % (acc_classifier/runs),\"%\")\n",
    "        print(\"Scikit model:\")\n",
    "        print(\"Average test accuracy: %.2f\" % (acc_scikit/runs),\"%\")\n",
    "        print(\"Bayes model:\")\n",
    "        print(\"Average test accuracy: %.2f\" % (acc_bayes/runs),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_outcome_data(X, y, included):       \n",
    "    \"\"\"\n",
    "    Returns the cross-validation groups for the outcome training.\n",
    "\n",
    "    :param X: The input matrix (ndarray)\n",
    "    :param y: The output vector (ndarray)\n",
    "    :param included: The classes to include (list)\n",
    "    \n",
    "    :return X_groups: The cross-validation groups for X (list)\n",
    "    :return y_groups: The cross-validation groups for y (list) \n",
    "        \n",
    "    \"\"\"  \n",
    "    # Get the number of samples to take from each class\n",
    "    data = []\n",
    "    num_cases = 0\n",
    "    num_classes = len(included)\n",
    "    for i in range(OUTCOMES_NUM): \n",
    "        if i in included:\n",
    "            cases = np.nonzero(y == i)[0]\n",
    "            if (num_cases):\n",
    "                num_cases = min(num_cases, len(cases))\n",
    "            else:\n",
    "                num_cases = len(cases)\n",
    "            data.append(cases) \n",
    "    \n",
    "    # Truncate to balance\n",
    "    for i in range(num_classes):\n",
    "        np.random.shuffle(data[i])\n",
    "        data[i] = data[i][0:num_cases]\n",
    "    \n",
    "    # Break into balanced groups\n",
    "    batch_groups = []\n",
    "    for i in range(num_classes):\n",
    "        batch_groups.append(np.array_split(data[i], CV_GROUPS))\n",
    "\n",
    "    # Put batches together \n",
    "    outcome_groups = []\n",
    "    for i in range(CV_GROUPS):\n",
    "        batch = []\n",
    "        for j in range(num_classes):\n",
    "            batch = np.concatenate([batch, batch_groups[j][i]])\n",
    "        np.random.shuffle(batch)\n",
    "        outcome_groups.append(batch.astype('int'))\n",
    "    \n",
    "    X_groups = []\n",
    "    y_groups = []\n",
    "    for i in range(CV_GROUPS):\n",
    "        X_groups.append(X[outcome_groups[i],:])\n",
    "        y_groups.append(y[outcome_groups[i]])\n",
    "        \n",
    "    return X_groups, y_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outcome_manual(X_groups, y_groups, included, lambda_val, details = True):\n",
    "    \"\"\"\n",
    "    Trains the manual model to predict the outcome of the disease.\n",
    "    \n",
    "    :param X_groups: The cross-validation groups for X (list)\n",
    "    :param y_groups: The cross-validation groups for y (list) \n",
    "    :param included: The classes to include (list)\n",
    "    :param lambda_val: Regularization parameter (float)\n",
    "    :param details: True for the full output (bool)\n",
    "    \n",
    "    :return: average test accuracy for one vs all model\n",
    "        \n",
    "    \"\"\" \n",
    "    train_accuracy = test_accuracy = train_f1_score = test_f1_score = 0 \n",
    "    num_classes = len(included)\n",
    "    test_confusion = np.zeros(shape=(len(included), len(included)))\n",
    "\n",
    "    target_names = []\n",
    "    for i in included:\n",
    "        target_names.append('class ' + str(i))\n",
    "\n",
    "    for i in range(CV_GROUPS):\n",
    "        X_test = X_groups[i]\n",
    "        y_test = y_groups[i]\n",
    "        X_train, y_train = get_train_groups(X_groups, y_groups, i)\n",
    "        \n",
    "        weight_vectors, intercepts = train_one_vs_all(X_train[:,1:], y_train, included, lambda_val)\n",
    "        train_preds = predict_one_vs_all(X_train[:,1:], weight_vectors, intercepts)\n",
    "        test_preds  = predict_one_vs_all(X_test[:,1:],  weight_vectors, intercepts)\n",
    "\n",
    "        accuracy, f1 = get_stats(y_train, train_preds)\n",
    "        train_accuracy = train_accuracy + accuracy\n",
    "        train_f1_score = train_f1_score + f1\n",
    "        \n",
    "        accuracy, f1 = get_stats(y_test, test_preds)\n",
    "        test_accuracy = test_accuracy + accuracy\n",
    "        test_f1_score = test_f1_score + f1\n",
    "        test_confusion = test_confusion + confusion_matrix(list(y_test), list(test_preds))\n",
    "        \n",
    "    if details:\n",
    "        print(\"Average train accuracy: %.2f\" % (train_accuracy/CV_GROUPS),\"%\")\n",
    "        print(\"Average train F1 score: %.2f\" % (train_f1_score/CV_GROUPS))\n",
    "\n",
    "        print(\"Average test accuracy: %.2f\" % (test_accuracy/CV_GROUPS),\"%\")\n",
    "        print(\"Average test F1 score: %.2f\" % (test_f1_score/CV_GROUPS))   \n",
    "        create_heatmap((test_confusion/CV_GROUPS).astype('int'), included)\n",
    "    return test_accuracy/CV_GROUPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outcome_scikit(X_groups, y_groups, included, feature_labels, details = True):\n",
    "    \"\"\"\n",
    "    Trains the scikit model to predict the outcome of the disease.\n",
    "    \n",
    "    :param X_groups: The cross-validation groups for X (list)\n",
    "    :param y_groups: The cross-validation groups for y (list) \n",
    "    :param included: The classes to include (list)\n",
    "    :param feature_labels: The feature labels (list)\n",
    "    :param details: True for the full output (bool)\n",
    "    \n",
    "    :return: Average logistic regression accuracy\n",
    "    :return: Average Bayes accuracy\n",
    "        \n",
    "    \"\"\" \n",
    "    train_accuracy = test_accuracy = train_f1_score = test_f1_score = bayes_f1_score = test_bayes = 0\n",
    "    test_weights = np.zeros(X_groups[0].shape[1] - 1)\n",
    "    test_confusion = np.zeros(shape=(len(included), len(included)))\n",
    "    \n",
    "    target_names = []\n",
    "    for i in included:\n",
    "        target_names.append('class ' + str(i))\n",
    "    \n",
    "    for i in range(CV_GROUPS):\n",
    "        X_test = X_groups[i]\n",
    "        y_test = y_groups[i]\n",
    "        X_train, y_train = get_train_groups(X_groups, y_groups, i)\n",
    "        \n",
    "        lr = sklm.LogisticRegression()\n",
    "        lr.fit(X_train[:,1:], y_train.astype('int'))\n",
    "        train_preds = lr.predict(X_train[:,1:])\n",
    "        test_preds = lr.predict(X_test[:,1:])    \n",
    "        \n",
    "        # Naive Bayes model\n",
    "        gnb = GaussianNB()\n",
    "        gnb.fit(X_train[:,1:], y_train.astype('int'))       \n",
    "        gnb_preds = gnb.predict(X_test[:,1:])\n",
    "        \n",
    "        train_accuracy = train_accuracy + np.mean(train_preds == y_train)*100\n",
    "        test_accuracy = test_accuracy + np.mean(test_preds == y_test)*100       \n",
    "        test_bayes = test_bayes + accuracy_score(list(y_test), list(gnb_preds))*100\n",
    "        train_class_report = classification_report(list(y_train), list(train_preds), \\\n",
    "                                              target_names = target_names, output_dict=True)\n",
    "        test_class_report = classification_report(list(y_test), list(test_preds), \\\n",
    "                                              target_names = target_names, output_dict=True)     \n",
    "        bayes_class_report = classification_report(list(y_test), list(gnb_preds), \\\n",
    "                                                   target_names = target_names, output_dict=True)\n",
    "\n",
    "        # Calculate average test f1-score\n",
    "        train_f1_score = train_f1_score + train_class_report['weighted avg']['f1-score']\n",
    "        test_f1_score = test_f1_score + test_class_report['weighted avg']['f1-score']\n",
    "        bayes_f1_score = bayes_f1_score + bayes_class_report['weighted avg']['f1-score']\n",
    "        test_weights = np.add(test_weights, lr.coef_[0])\n",
    "        test_confusion = test_confusion + confusion_matrix(list(y_test), list(test_preds))\n",
    "    \n",
    "    actual_labels, actual_weights = get_actual_weights(feature_labels[1:], list(test_weights))   \n",
    "    test_weights_abs = list(np.abs(actual_weights))\n",
    "    test_weights_sorted = test_weights_abs.copy()\n",
    "    test_weights_sorted.sort(reverse = True)\n",
    "    \n",
    "    if details:\n",
    "        print(\"Average train accuracy: %.2f\" % (train_accuracy/CV_GROUPS),\"%\")\n",
    "        print(\"Average train F1 score: %.2f\" % (train_f1_score/CV_GROUPS))\n",
    "        print(\"Average test accuracy: %.2f\" % (test_accuracy/CV_GROUPS),\"%\")\n",
    "        print(\"Average test F1 score: %.2f\" % (test_f1_score/CV_GROUPS))\n",
    "        print(\"Average Gaussian Naive Bayes accuracy: %.2f\" % (test_bayes/CV_GROUPS),\"%\")\n",
    "        print(\"Average Gaussian Naive Bayes F1 score: %.2f\" % (bayes_f1_score/CV_GROUPS))\n",
    "        create_heatmap((test_confusion/CV_GROUPS).astype('int'), included)\n",
    "        print()\n",
    "        print(\"Highest average weights (absolute values!):\")\n",
    "        for i in range(len(test_weights_sorted[:3])):\n",
    "            index = test_weights_abs.index(test_weights_sorted[i])\n",
    "            print(actual_labels[index], ': %.2f' % test_weights_sorted[i])\n",
    "    return test_accuracy/CV_GROUPS, test_bayes/CV_GROUPS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Helpers: Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_vs_all(X, y, included, lambda_val):\n",
    "    \"\"\"\n",
    "    Trains a one vs. all logistic regression\n",
    "    \n",
    "    :param X: The input matrix (ndarray)\n",
    "    :param y: Label vector (ndarray)\n",
    "    :param included: Indices of the outcomes included in training (ndarray)\n",
    "    :param lambda_val: Regularization parameter (float)\n",
    "\n",
    "    :return weight_vectors: Weight vector matrix (ndarray)\n",
    "    :return intercepts: Intercept vector matrix (ndarray)                     \n",
    "            \n",
    "    \"\"\"\n",
    "    num_classes = len(included)\n",
    "    weight_vectors = np.zeros((X.shape[1], num_classes))\n",
    "    intercepts = np.zeros(num_classes) \n",
    "\n",
    "    for i in range(len(included)):\n",
    "        if included[i] in y:\n",
    "            y_c = (y == included[i]).astype(int)\n",
    "            weight_vectors[:, i], intercepts[i] = train_logistic_regression(X, y_c, lambda_val)\n",
    "    return weight_vectors, intercepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_one_vs_all(X, weight_vectors, intercepts):\n",
    "    \"\"\"\n",
    "    Predicts one vs. all logistic regression\n",
    "    \n",
    "    :param X: The input matrix (ndarray)\n",
    "    :param weight_vectors: Weight vector matrix (ndarray)\n",
    "    :param intercepts: Intercept vector matrix (ndarray)     \n",
    "                       \n",
    "    :return predictions: Prediction vector (ndarray) \n",
    "    \n",
    "    \"\"\"    \n",
    "    predictions = np.argmax(np.add(np.dot(X,weight_vectors),intercepts), 1)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_logistic_regression(X, y, lambda_val):\n",
    "    \"\"\"\n",
    "    Trains a regularized logistic regression model\n",
    "    \n",
    "    :param X: The input matrix (ndarray)\n",
    "    :param y: Label vector (ndarray)\n",
    "    :param lambda_val: Regularization parameter (float)\n",
    "\n",
    "    :return weights: Weight vector (ndarray)\n",
    "    :return intercept: Intercept parameter (float)   \n",
    "    \n",
    "    \"\"\"\n",
    "    model = sklm.LogisticRegression(C=2./lambda_val, solver='lbfgs')\n",
    "\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        model.fit(X, y)\n",
    "\n",
    "    weight_vector = model.coef_.ravel()\n",
    "    intercept = model.intercept_\n",
    "    return weight_vector, intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic(z):\n",
    "    \"\"\"\n",
    "    The logistic function\n",
    "    \n",
    "    :param z: Array to be converted (ndarray)\n",
    "    \n",
    "    :return p: logistic(z) entrywise of the same shape (ndarray)\n",
    "    \n",
    "    \"\"\"\n",
    "    ones_z = np.ones(z.shape)\n",
    "    exp = np.full(z.shape, np.e)\n",
    "    denum = ones_z.copy() + np.power(exp, -z)\n",
    "    p = np.divide(ones_z, denum)\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nll_cost_function(X, y, theta):\n",
    "    \"\"\"\n",
    "    Computes the negative log liklihood (nll) cost function for a particular data \n",
    "    set and hypothesis (weight vector)\n",
    "    \n",
    "    :param X: The input matrix (ndarray)\n",
    "    :param y: Label vector (ndarray)\n",
    "    :param theta: Initial parameter vector (ndarray)\n",
    "    \n",
    "    :return cost: The value of the cost function (float)\n",
    "    \n",
    "    \"\"\"\n",
    "    cost = 0\n",
    "    h = logistic(np.dot(X,theta)).astype('int')\n",
    "    cost = -np.dot(y, np.log(h)) - np.dot((1-y), np.log(1 - h))\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X, y, theta, alpha, iters):\n",
    "    \"\"\"\n",
    "    Fits a logistic regression model by gradient descent.\n",
    "    \n",
    "    :param X: The input matrix (ndarray)\n",
    "    :param y: Label vector (ndarray)\n",
    "    :param theta: Initial parameter vector (ndarray)\n",
    "    :param alpha: Step size (float)\n",
    "    :param iters: Number of iterations (int)\n",
    "    \n",
    "    :return theta: Learned parameter vector (ndarray)\n",
    "    :return J_history: Cost function in iteration (ndarray)\n",
    "        \n",
    "    \"\"\"\n",
    "    J_history = np.zeros(iters)\n",
    "    \n",
    "    for i in range(iters):\n",
    "        d_J = 2*(np.dot(X.T, np.subtract(logistic(np.dot(X,theta)),y)))\n",
    "        theta = theta - (alpha*d_J)\n",
    "        J_history[i] = nll_cost_function(X, y, theta)\n",
    "    return theta, J_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent_v2(X, y, alpha, iters, theta=None):\n",
    "    \"\"\"\n",
    "    Gradient descent function for the life expectancy training.\n",
    "    \n",
    "    :param X: The input matrix (ndarray)\n",
    "    :param y: Label vector (ndarray)\n",
    "    :param alpha: Step size (float)\n",
    "    :param iters: The number of gradient descent iterations (int)\n",
    "    :param theta: Initial parameter vector (ndarray)\n",
    "\n",
    "    :return theta: Learned parameter vector (ndarray)\n",
    "    :return J_history: Cost function in iteration (ndarray)                    \n",
    "            \n",
    "    \"\"\"\n",
    "    m,n = X.shape\n",
    "    if theta is None:\n",
    "        theta = np.ones(n)  \n",
    "    J_history = np.zeros(iters)\n",
    "\n",
    "    for i in range(0, iters):       \n",
    "        theta = theta - np.dot(alpha*X.T, np.dot(X, theta) - y)\n",
    "        J_history[i] = cost_function_v2(X, y, theta)    \n",
    "    return theta, J_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_function_v2(X, y, theta):\n",
    "    \"\"\"\n",
    "    Calculates the cost for the life expectancy training.\n",
    "    \n",
    "    :param X: The input matrix (ndarray)\n",
    "    :param y: Label vector (ndarray)\n",
    "    :param theta: Initial parameter vector (ndarray)\n",
    "\n",
    "    :return cost: The training cost (float)                 \n",
    "            \n",
    "    \"\"\"\n",
    "    cost = 0\n",
    "    diff = (np.dot(X,theta)-y).T\n",
    "    diff = np.where(abs(diff) < 30, 0, diff)\n",
    "    cost = 0.5*np.dot(diff, diff)\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_v2(M):\n",
    "    \"\"\"\n",
    "    Normalizes the data of the input matrix.\n",
    "    \n",
    "    :param M: The input matrix (ndarray)\n",
    "\n",
    "    :return norm_M: The normalized matrix (ndarray)                 \n",
    "            \n",
    "    \"\"\"\n",
    "    norm_M = M.copy()\n",
    "    mean = np.mean(M[:, 1:].copy(), axis = 0)\n",
    "    std = np.array(np.std(M[:, 1:].copy(), axis = 0))\n",
    "    norm_M[:,1:] = np.divide(np.subtract(norm_M[:,1:], mean), std)\n",
    "    return norm_M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Helpers: Statistics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_groups(X_groups, y_groups, test_group):\n",
    "    \"\"\"\n",
    "    Returns the assembled train set without the test group\n",
    "\n",
    "    :param X_groups: The cross-validation groups for reduced X (list)\n",
    "    :param y_groups: The cross-validation groups for reduced y (list) \n",
    "    :param test_group: The test group index (int)\n",
    "    \n",
    "    :return X_train: The assembled train batch for X\n",
    "    :return y_train: The assembled train batch for y\n",
    "        \n",
    "    \"\"\"  \n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    for i in range(CV_GROUPS):\n",
    "        if (i != test_group):\n",
    "            if len(X_train) == 0:\n",
    "                X_train = np.array(X_groups[i])\n",
    "                y_train = np.array(y_groups[i])\n",
    "            else:\n",
    "                X_train = np.concatenate((X_train, X_groups[i]))\n",
    "                y_train = np.concatenate((y_train, y_groups[i]))\n",
    "    return X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats(trues, predictions):\n",
    "    \"\"\"\n",
    "    Calculates the accuracy and F1 score, given the expected/predicted values.\n",
    "\n",
    "    :param trues: The expected values (list)\n",
    "    :param predictions: The predicted values (list) \n",
    "    \n",
    "    :return accuracy: The prediction accuracy\n",
    "    :return y_train: The prediction F1 score\n",
    "        \n",
    "    \"\"\"  \n",
    "    stat_zip = zip(predictions, trues)\n",
    "    \n",
    "    match = tp = fp = fn = 0\n",
    "    for x in stat_zip:\n",
    "        if x[0] != x[1] and x[0] == 1:\n",
    "            fp = fp + 1\n",
    "        elif x[0] != x[1] and x[0] == 0:\n",
    "            fn = fn + 1\n",
    "        elif x[0] == x[1]:\n",
    "            match = match + 1\n",
    "            if x[0] == 1:\n",
    "                tp = tp + 1\n",
    "    \n",
    "    accuracy = match/len(trues)*100   \n",
    "    precision = 0 if (tp + fp == 0) else tp/(tp + fp)\n",
    "    recall = 0 if (tp + fn == 0) else tp/(tp + fn)\n",
    "    f1 = 0 if (precision + recall == 0) else 2*precision*recall/(precision + recall)\n",
    "    \n",
    "    return accuracy, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_num_samples(y):\n",
    "    \"\"\"\n",
    "    Prints out the number of samples of each class.\n",
    "\n",
    "    :param y: The y values (list)\n",
    "\n",
    "    \"\"\"  \n",
    "    for i in range(OUTCOMES_NUM): \n",
    "        print(\"Samples of class\", i, \":\", len(np.nonzero(y == i)[0]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_actual_weights(feature_labels, weights):\n",
    "    \"\"\"\n",
    "    Gets the average (compressed) weights to assess feature importance. \n",
    "\n",
    "    :param feature_labels: The feature labels (list)\n",
    "    :param weights: The feature weights (list)\n",
    "    \n",
    "    :return actual_labels: The labels applicable to the set (list)\n",
    "    :return weights: The compressed feature weights (list)\n",
    "\n",
    "    \"\"\"  \n",
    "    actual_labels = []\n",
    "\n",
    "    compressed_labels = ['histological_grade', 'clinical_stage', 'tumor_grade', 'histological_type', 'tumor_stage']\n",
    "    compressed_indices = []\n",
    "    for i in range(len(compressed_labels)):\n",
    "        compressed_indices.append([])\n",
    "\n",
    "    # extract actual labels\n",
    "    for i in range(len(feature_labels)):  \n",
    "        success = False\n",
    "        for j in range(len(compressed_labels)):\n",
    "            if feature_labels[i].startswith(compressed_labels[j]):\n",
    "                compressed_indices[j].append(i)\n",
    "                if compressed_labels[j] not in actual_labels:\n",
    "                    actual_labels.append(compressed_labels[j])\n",
    "                success = True\n",
    "                break\n",
    "        if not success:\n",
    "            actual_labels.append(feature_labels[i])\n",
    "    compressed_indices.sort(reverse = True)\n",
    "\n",
    "    # compress weights\n",
    "    for i in range(len(compressed_indices)):\n",
    "        if compressed_indices[i]:\n",
    "            num_elem = len(compressed_indices[i]) \n",
    "            start = compressed_indices[i][0]\n",
    "            finish = compressed_indices[i][0] + num_elem\n",
    "            weights[start : finish] = [np.mean( weights[start : finish])]\n",
    "    return actual_labels, weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Helpers: Visual**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_heatmap(cnf_matrix, included):\n",
    "    \"\"\"\n",
    "    Creates the heatmap of the confusion matrix.\n",
    "    \n",
    "    :param cnf_matrix: The confusion matrix (ndarray)\n",
    "    :param included: The classes to include (list)\n",
    "    \n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots()\n",
    "    tick_marks = np.arange(len(included))\n",
    "    plt.xticks(tick_marks)\n",
    "    plt.yticks(tick_marks)\n",
    "\n",
    "    # create heatmap\n",
    "    sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"YlGnBu\" ,fmt='g')\n",
    "    ax.xaxis.set_label_position(\"top\")\n",
    "    \n",
    "        \n",
    "    labels_X = [item.get_text() for item in ax.get_xticklabels()]\n",
    "    labels_Y = [item.get_text() for item in ax.get_yticklabels()]\n",
    "    for i in range(len(included)):\n",
    "        labels_X[i] = included[i]\n",
    "        labels_Y[i] = included[i]\n",
    "    ax.set_xticklabels(labels_X)\n",
    "    ax.set_yticklabels(labels_Y)\n",
    "\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.title('Confusion matrix', y=1.1)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label') \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_lambdas(X_groups, y_groups, included):\n",
    "    \"\"\"\n",
    "    Plots the accuracy of the one-vs-all model for several different lambdas.\n",
    "    \n",
    "    :param X_groups: The cross-validation groups for X (list)\n",
    "    :param y_groups: The cross-validation groups for y (list) \n",
    "    :param included: The number of gradient descent iterations (int)\n",
    "    \n",
    "    \"\"\"\n",
    "    train_accuracy = test_accuracy = 0\n",
    "    num_classes = len(included)\n",
    "\n",
    "    lambda_vals = 10.0 ** np.linspace(-5, 5, 11)\n",
    "    test_acc = np.zeros(lambda_vals.size)\n",
    "    train_acc = np.zeros(lambda_vals.size)\n",
    "\n",
    "    for j in range(lambda_vals.size): \n",
    "        train_accuracy = test_accuracy = 0\n",
    "\n",
    "        for i in range(CV_GROUPS):\n",
    "            X_test = X_groups[i]\n",
    "            y_test = y_groups[i]\n",
    "            X_train, y_train = get_train_groups(X_groups, y_groups, i)\n",
    "\n",
    "            weight_vectors, intercepts = train_one_vs_all(X_train, y_train, included, lambda_vals[j])\n",
    "            train_preds = predict_one_vs_all(X_train, weight_vectors, intercepts)\n",
    "            test_preds  = predict_one_vs_all(X_test, weight_vectors, intercepts)\n",
    "\n",
    "            train_accuracy = train_accuracy + np.mean(train_preds == y_train)*100\n",
    "            test_accuracy = test_accuracy + np.mean(test_preds == y_test)*100 \n",
    "\n",
    "        train_acc[j] = train_accuracy/CV_GROUPS\n",
    "        test_acc[j] = test_accuracy/CV_GROUPS\n",
    "\n",
    "    plt.xlabel('lambda (log10)')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xscale('log')\n",
    "    plt.plot(lambda_vals, train_acc, 'bo', linestyle='dashed')\n",
    "    plt.plot(lambda_vals, test_acc, 'go', linestyle='dashed')\n",
    "    plt.legend(('train', 'test')) \n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
